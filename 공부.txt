1. Transformer의 핵심 구조적 특징은 무엇인가?
① Convolution Layer ② Attention Mechanism ③ Recurrent Loop ④ Gradient Clipping

2. Self-Attention의 주요 목적은?
① 입력 간 관계 파악 ② 모델 복잡도 감소 ③ 파라미터 수 감소 ④ 손실 최소화

3. LLM의 입력 단위인 토큰(Token)의 의미는?
① 단어 또는 단어 조각 ② 문장 단위 ③ 문서 전체 ④ 문단

4. Fine-tuning의 주요 목적은?
① 특정 도메인에 모델 적응 ② 데이터 전처리 효율화 ③ 모델 파라미터 감소 ④ 새로운 모델 구조 설계

5. Prompt-tuning과 Fine-tuning의 차이는?
① Prompt-tuning은 소수 파라미터만 조정 ② Fine-tuning은 임베딩만 수정 ③ Fine-tuning은 입력문 수정 ④ Prompt-tuning은 전체 파라미터 수정

6. Transformer의 Encoder가 주로 하는 일은?
① 입력 문맥 인코딩 ② 모델 평가 ③ 텍스트 생성 ④ 확률 계산

7. Transformer의 Decoder의 역할은?
① 문장 생성 ② 모델 학습 가속 ③ 토큰화 수행 ④ 입력 특징 추출

8. Attention Score 계산에 사용되는 세 요소는?
① Query, Key, Value ② Input, Output, Weight ③ Node, Edge, Weight ④ Token, Layer, Bias

9. LLM의 컨텍스트 윈도우(Context Window)는?
① 입력 가능한 최대 토큰 길이 ② 모델 학습 속도 ③ 배치 크기 ④ 학습률

10. Embedding의 주요 목적은?
① 텍스트를 수치 벡터로 표현 ② 데이터 정규화 ③ 손실 보정 ④ 모델 크기 축소

11. RAG(Retrieval-Augmented Generation)의 핵심 아이디어는?
① 생성 모델에 외부 검색 결합 ② 모델 경량화 ③ 생성 속도 향상 ④ 미세조정 자동화

12. Vector Database의 주된 역할은?
① 벡터 기반 유사도 검색 ② 관계형 데이터 쿼리 ③ 데이터베이스 정규화 ④ 모델 가중치 저장

13. LLM 응답의 일관성 향상을 위한 기술은?
① Beam Search ② Weight Decay ③ Gradient Clipping ④ Batch Normalization

14. LLM의 할루시네이션(Hallucination) 완화 방법은?
① 외부 지식 소스 참조 ② 무작위 토큰 삽입 ③ 학습률 증가 ④ 드롭아웃 제거

15. NeMo Framework의 주요 목적은?
① 대형 언어 모델 구축·튜닝 지원 ② GPU 클러스터 관리 ③ 데이터 압축 ④ 시각화 도구 제공

16. Triton Inference Server의 기능은?
① 모델 배포 및 추론 서비스 제공 ② 하이퍼파라미터 최적화 ③ GPU 전력 관리 ④ 데이터셋 라벨링

17. TensorRT의 주된 용도는?
① 추론 속도 최적화 ② 모델 학습 자동화 ③ 데이터 전처리 ④ 오디오 변환

18. NVIDIA의 Riva는 주로 어떤 기능에 사용되는가?
① 음성 인식·합성 ② 시각적 객체 탐지 ③ 이미지 변환 ④ 데이터베이스 관리

19. Python에서 LLM API 호출 시 일반적으로 사용하는 방식은?
① REST API ② FTP Request ③ Socket Stream ④ SQL Query

20. PyTorch의 기본 구성 요소 중 텐서(Tensor)는 무엇인가?
① 다차원 배열 구조 ② 손실 함수 ③ 모델 구조체 ④ 파이썬 함수

21. 학습 데이터와 검증 데이터를 구분하는 이유는?
① 오버피팅 방지 및 일반화 검증 ② 손실 계산 단순화 ③ 학습 속도 향상 ④ 메모리 절약

22. 과적합(Overfitting)을 방지하기 위한 방법은?
① Dropout 사용 ② Batch Size 감소 ③ Epoch 수 증가 ④ Learning Rate 증가

23. 하이퍼파라미터 튜닝의 주 목적은?
① 최적 성능 조합 탐색 ② 데이터 증강 ③ 손실함수 변경 ④ 모델 구조 변경

24. 성능 평가 지표 중 정밀도(Precision)는?
① 예측 중 실제 양성의 비율 ② 오차 제곱 평균 ③ 재현율과 동일 ④ 실제 양성 중 예측된 양성의 비율

25. F1 Score는 어떤 두 지표의 조화평균인가?
① Precision과 Recall ② 손실과 학습률 ③ 정확도와 손실 ④ Precision과 Accuracy

26. 지도학습(Supervised Learning)의 특징은?
① 라벨 데이터 사용 ② 비지도 데이터 사용 ③ 강화학습 기반 ④ 레이블 불필요

27. 비지도학습(Unsupervised Learning)의 목적은?
① 데이터 구조 파악 ② 예측 정확도 향상 ③ 피드백 기반 학습 ④ 보상 최대화

28. 강화학습(Reinforcement Learning)의 핵심 개념은?
① 보상 기반 학습 ② 비지도 학습 ③ 회귀분석 ④ 클러스터링

29. 손실 함수(Loss Function)의 역할은?
① 모델의 오류 측정 ② GPU 메모리 관리 ③ 모델 크기 조정 ④ 학습률 계산

30. 실험 관리 도구 MLflow의 기능은?
① 실험 추적 및 버전 관리 ② 하이퍼파라미터 자동 튜닝 ③ API 통합 ④ 데이터 시각화 전용

31. 데이터 전처리 과정에서 결측값 처리는?
① 제거 또는 대체 ② 무시 ③ 정규화로 해결 ④ 무작위 변경

32. 데이터 스케일링의 목적은?
① 모델 입력 균형 맞추기 ② 손실 계산 가속 ③ 시각화 개선 ④ 샘플 수 증가

33. Pandas의 주요 역할은?
① 데이터 분석과 조작 ② 모델 평가 ③ 시각화 ④ 신경망 구성

34. Matplotlib은 주로 어떤 용도로 사용되는가?
① 시각화 ② 데이터 변환 ③ 벡터 연산 ④ 하이퍼튜닝

35. Explainable AI(XAI)의 목적은?
① 모델 의사결정 해석 가능성 향상 ② 모델 압축 ③ 성능 최대화 ④ 데이터 증강

36. 공정성(Fairness) 확보의 핵심은?
① 편향 최소화 ② 계산 효율화 ③ 속도 최적화 ④ 정밀도 향상

37. LLM 응답의 안전성(Safety) 강화를 위한 방법은?
① 콘텐츠 필터링 및 정책 설정 ② 모델 압축 ③ 학습률 감소 ④ 입력 샘플링

38. AI 편향(Bias)의 주요 원인은?
① 불균형 데이터 ② GPU 성능 부족 ③ 드롭아웃 설정 ④ 모델 크기

39. Responsible AI가 중시하는 요소는?
① 공정성·투명성·책임성 ② 성능·속도·비용 ③ 정확도·정밀도·재현율 ④ 오차·잡음·편향

40. Explainability를 향상시키는 기법은?
① LIME, SHAP ② PCA ③ Adam Optimizer ④ Dropout

41. NVIDIA NeMo Guardrails의 역할은?
① 대화형 AI의 안전성과 제어 ② GPU 성능 향상 ③ 음성 합성 ④ 데이터 병렬 처리

42. 모델 재현성(Reproducibility)을 확보하기 위한 조치는?
① 시드 고정 및 버전 관리 ② 하이퍼튜닝 자동화 ③ 데이터 증강 ④ 랜덤성 증가

43. 모델 성능 비교 시 공정성을 위해 필요한 것은?
① 동일한 평가 데이터 ② GPU 동일 모델 ③ 임의 배치 ④ 코드 난수화

44. Python에서 API 요청 시 자주 사용하는 라이브러리는?
① requests ② pandas ③ numpy ④ matplotlib

45. LLM 기반 서비스에서 RAG 구조의 장점은?
① 최신 정보 반영 가능 ② 모델 크기 축소 ③ 학습 데이터 감소 ④ 토큰 절약

46. LLM의 출력 확률을 조절하는 temperature 값이 높을수록?
① 무작위성 증가 ② 결정적 응답 ③ 일관성 증가 ④ 출력 길이 감소

47. 모델 평가 지표 중 Recall은?
① 실제 양성 중 예측 양성 비율 ② 예측 음성 중 실제 음성 비율 ③ F1 Score와 동일 ④ 손실 최소화율

48. GPU 병렬처리가 유리한 이유는?
① 대량 행렬 연산 병렬화 가능 ② 저장공간 많음 ③ RAM 속도 빠름 ④ CPU보다 전력 소모 적음

49. LLM 개발 시 토큰화(tokenization)의 역할은?
① 텍스트를 모델 입력 단위로 분리 ② GPU 초기화 ③ 손실 계산 ④ 모델을 저장

50. Generative AI의 대표적 응용 분야는?
① 텍스트·이미지·음성 생성 ② 모델 평가 ③ 코드 압축 ④ 데이터베이스 관리

51. Large Language Model(LLM)에서 Fine-tuning의 주요 이점은?
① 특정 도메인에 모델 적응 ② 모델 크기 축소 ③ 학습 데이터 자동 생성 ④ 파라미터 감소

52. Transformer의 Attention Mechanism에서 Query-Key 유사도는 어떤 값으로 계산되는가?
① 점곱(dot product) ② 행렬식 ③ 거리 기반 함수 ④ 평균값

53. Layer Normalization의 목적은?
① 학습 안정화 및 수렴 향상 ② 모델 크기 감소 ③ 데이터 스케일 조정 ④ 손실 보정

54. Positional Encoding은 어떤 역할을 하는가?
① 단어 순서 정보 추가 ② 벡터 크기 축소 ③ 토큰 분리 ④ 손실 감소

55. LLM에서 Parameter 수가 많을수록 일반적으로 기대되는 효과는?
① 표현력 향상 ② 추론 속도 향상 ③ 학습 속도 향상 ④ 메모리 절약

56. Attention의 Softmax 단계는 어떤 역할을 하는가?
① 가중치 정규화 ② 손실 최소화 ③ Dropout 적용 ④ ReLU 활성화

57. Encoder-Decoder 구조의 대표적 응용은?
① 번역기 ② 이미지 분류기 ③ 추천 시스템 ④ 회귀 분석

58. HuggingFace Transformers 라이브러리의 주요 기능은?
① 사전 학습된 모델 불러오기 및 파인튜닝 ② GPU 제어 ③ 시각화 도구 제공 ④ 데이터 증강

59. Prompt Engineering의 주요 목적은?
① 모델 응답 품질 향상 ② 토큰화 가속 ③ 학습률 조정 ④ GPU 효율 향상

60. Temperature 하이퍼파라미터가 낮을 때 LLM의 출력 특징은?
① 결정적이고 일관된 응답 ② 무작위성 증가 ③ 창의적 응답 증가 ④ 불안정 출력

61. Top-k 샘플링은 어떤 기법인가?
① 확률이 높은 상위 k개 토큰만 선택 ② 손실 상위 k개 필터 제거 ③ 학습률 k배 증가 ④ k개 문장 병합

62. Top-p(=Nucleus) 샘플링은?
① 누적 확률이 p 이하인 토큰 집합에서 샘플링 ② k개 확률 평균화 ③ p개의 문장 분리 ④ 확률 최대값 선택

63. Tokenization 과정의 주된 목표는?
① 텍스트를 모델이 이해할 수 있는 단위로 분할 ② 모델 학습률 조절 ③ 데이터 정규화 ④ 확률 계산

64. Subword 토크나이징의 장점은?
① 희귀 단어 처리 유연성 ② 문장 길이 고정 ③ 손실 함수 단순화 ④ 계산 속도 향상

65. 모델의 Generalization을 높이려면?
① 다양한 데이터와 적절한 정규화 ② Epoch 증가 ③ Dropout 제거 ④ 손실 가중치 감소

66. Batch Normalization의 효과는?
① 학습 안정화 및 속도 향상 ② 손실 최소화 ③ 파라미터 감소 ④ 모델 단순화

67. Activation Function 중 ReLU의 주요 장점은?
① Gradient 소실 완화 ② 계산량 감소 ③ 학습률 향상 ④ 손실 제어

68. Cross-Entropy Loss는 주로 어떤 문제에 사용되는가?
① 분류 문제 ② 회귀 문제 ③ 강화학습 ④ 클러스터링

69. 학습률(Learning Rate)이 너무 높으면?
① 발산(unstable) ② 수렴 빠름 ③ 정확도 향상 ④ 손실 최소화

70. Optimizer 중 Adam의 특징은?
① Adaptive 학습률과 모멘텀 결합 ② 고정 학습률 사용 ③ 확률적 손실 추정 ④ 가중치 정규화

71. Dropout의 목적은?
① 과적합 방지 ② 학습 속도 향상 ③ 손실 감소 ④ 파라미터 증가

72. Early Stopping의 역할은?
① 과적합 방지를 위해 학습 조기 종료 ② GPU 과열 방지 ③ 데이터 증강 제한 ④ 학습률 고정

73. Gradient Vanishing 문제를 완화하기 위한 방법은?
① ReLU 사용 ② Dropout 제거 ③ 학습률 감소 ④ 손실 증가

74. 하이퍼파라미터 탐색 자동화 도구로 유명한 것은?
① Optuna ② Matplotlib ③ PyTorch Lightning ④ Numpy

75. RAG 시스템에서 검색 단계는 주로 무엇을 수행하는가?
① 외부 문서에서 관련 정보 벡터 검색 ② 모델 응답 생성 ③ 텍스트 정규화 ④ 토큰화 수행

76. LLM의 응답에서 맥락 유지 향상을 위해 사용하는 구조는?
① Attention ② Dropout ③ Convolution ④ ReLU

77. LLM의 학습에서 Fine-tuning과 In-context Learning의 차이는?
① Fine-tuning은 파라미터 업데이트, In-context는 입력 기반 적응 ② 둘 다 파라미터 조정  
③ Fine-tuning은 프롬프트 수정, In-context는 모델 수정 ④ 동일 개념

78. 데이터셋 분할 시 일반적인 비율은?
① train 80%, val 10%, test 10% ② train 50%, test 50% ③ train 70%, val 30% ④ train 90%, test 10%

79. Cross-validation의 목적은?
① 데이터 의존성 완화 및 일반화 성능 검증 ② 학습률 조정 ③ GPU 최적화 ④ 배치 사이즈 설정

80. ROC 곡선에서 AUC 값이 의미하는 것은?
① 분류기의 전체 성능 ② 손실 변화율 ③ 정규화 정도 ④ 데이터 크기

81. Precision-Recall 곡선은 어떤 데이터셋에 더 적합한가?
① 불균형 데이터셋 ② 균형 데이터셋 ③ 시계열 데이터 ④ 잡음 많은 데이터

82. Outlier(이상치)를 처리하는 방법으로 옳은 것은?
① 제거하거나 변환 ② 무시 ③ 학습률 조정 ④ 데이터 병합

83. Feature Scaling 기법 중 StandardScaler는?
① 평균 0, 분산 1로 변환 ② 0~1 정규화 ③ 로그 스케일 변환 ④ 원-핫 인코딩

84. Pandas의 DataFrame은 무엇인가?
① 2차원 테이블 형태의 데이터 구조 ② 벡터 ③ 그래프 구조 ④ 텍스트 파일 포맷

85. Matplotlib에서 plt.plot()의 기본 용도는?
① 선 그래프 그리기 ② 막대 그래프 ③ 산점도 ④ 히스토그램

86. AI 모델의 Explainability를 높이기 위한 프레임워크는?
① SHAP, LIME ② NumPy, Pandas ③ CUDA, cuDNN ④ Triton, TensorRT

87. Responsible AI에서 ‘투명성(Transparency)’이란?
① 모델 의사결정 과정을 설명할 수 있음 ② 데이터 암호화 ③ GPU 자원 공개 ④ 코드 오픈소스화

88. Trustworthy AI가 강조하는 세 가지 핵심 요소는?
① 공정성, 안전성, 설명가능성 ② 속도, 효율, 정확도 ③ 비용, 품질, 성능 ④ 가용성, 투명성, 병렬성

89. LLM의 할루시네이션 문제는 주로 어떤 원인인가?
① 사실 정보 부족 ② 모델 크기 과도 ③ 학습률 과소 ④ 토큰화 오류

90. NeMo Guardrails의 주된 사용 목적은?
① LLM 응답 안전성 강화 ② GPU 성능 개선 ③ 모델 경량화 ④ 음성 합성

91. NVIDIA Triton이 제공하는 주요 기능은?
① 모델 추론 서비스 ② 데이터 증강 ③ 시각화 ④ 학습 파이프라인 생성

92. TensorRT의 최적화 방식 중 하나는?
① 연산 그래프 병합 및 양자화 ② 데이터 정규화 ③ 손실 가중치 조정 ④ 배치 샘플링

93. NeMo Toolkit의 구성 요소로 옳은 것은?
① 모델 구성, 학습, 배포 지원 ② GPU 모니터링 ③ 네트워크 관리 ④ 이미지 증강

94. LLM 실험 관리에 사용되는 대표 오픈소스는?
① MLflow, Weights & Biases ② TensorBoard, CUDA ③ Optuna, cuDNN ④ Keras, Flask

95. 데이터 편향(bias)을 줄이기 위한 방법은?
① 데이터 다양성 확보 및 밸런싱 ② 모델 크기 축소 ③ 학습률 증가 ④ Dropout 추가

96. LLM에서 "context length"가 긴 모델의 장점은?
① 더 긴 대화 맥락 이해 가능 ② 추론 속도 향상 ③ 학습률 증가 ④ 파라미터 감소

97. Prompt-tuning의 장점은?
① 적은 파라미터로 빠른 적응 ② 모든 가중치 수정 ③ 모델 구조 변경 ④ 대규모 학습 필요

98. GPU 가속의 핵심 원리는?
① 병렬 연산을 통한 처리 속도 향상 ② CPU 제어 완화 ③ 데이터 압축 ④ 토큰 수 감소

99. Fine-tuning 데이터셋의 품질이 낮을 경우?
① 모델 성능 저하 및 편향 증가 ② 일반화 향상 ③ 메모리 감소 ④ 속도 증가

100. Responsible AI의 궁극적 목표는?
① 신뢰할 수 있고 윤리적인 AI 구축 ② 처리속도 향상 ③ 모델 크기 축소 ④ 사용자 데이터 수집

101. 실험 재현성(Reproducibility)을 확보하기 위해 필요한 조치는?
① 시드 고정 및 버전 관리 ② 하이퍼튜닝 자동화 ③ 데이터 증강 ④ 무작위 초기화

102. 모델 학습 실험에서 하이퍼파라미터 튜닝의 주요 목적은?
① 최적 성능 조합 탐색 ② 모델 구조 단순화 ③ 학습 데이터 축소 ④ 오버피팅 유도

103. Cross-validation을 사용하는 이유는?
① 일반화 성능 검증 및 데이터 편향 완화 ② 학습 속도 향상 ③ GPU 효율 증가 ④ 손실 최소화

104. Early stopping이 과적합을 줄이는 이유는?
① 검증 손실 증가 시 학습 중단 ② 학습률 감소 ③ 파라미터 동결 ④ 데이터 증강 중단

105. Learning rate scheduler의 역할은?
① 학습 진행에 따라 학습률 조정 ② 모델 크기 조절 ③ Dropout 조절 ④ 배치 크기 고정

106. 실험 로깅(logging)이 중요한 이유는?
① 결과 추적 및 재현 가능성 확보 ② 모델 구조 단순화 ③ 파라미터 감소 ④ GPU 메모리 절약

107. MLflow의 주요 기능은?
① 실험 기록 및 모델 버전 관리 ② 데이터 정규화 ③ 하이퍼튜닝 자동화 ④ 시각화 전용

108. Weights & Biases(W&B)의 주요 장점은?
① 실험 추적, 시각화, 협업 기능 제공 ② GPU 가속 지원 ③ 자동 데이터 정제 ④ 모델 양자화

109. 실험 관리 도구의 공통 목적은?
① 재현성 확보와 성능 비교 용이 ② 코드 압축 ③ 학습률 자동화 ④ 모델 저장 용량 감소

110. Grid Search의 단점은?
① 계산 비용 높음 ② 탐색 불가능 ③ 무작위성 증가 ④ 정확도 낮음

111. Random Search의 장점은?
① 효율적 탐색 가능 ② 재현성 향상 ③ 계산량 최소 ④ 완전 탐색

112. Bayesian Optimization의 특징은?
① 확률 모델을 사용해 효율적 탐색 ② 무작위 시도 ③ 모든 조합 탐색 ④ 규칙 기반 탐색

113. 하이퍼파라미터 탐색 시 성능 비교 기준으로 사용하는 지표는?
① Validation score ② Training loss ③ Gradient 평균 ④ 파라미터 수

114. 실험 결과를 정량적으로 비교하려면?
① 공통 데이터셋과 지표 사용 ② 임의 샘플링 ③ 모델 구조 변경 ④ 학습률 변경

115. Reproducibility 확보를 위해 로그에 기록해야 할 항목은?
① 하이퍼파라미터, 데이터 버전, 코드 커밋 ② GPU 전력소모 ③ 코드 실행 시간만 ④ 모델 크기만

116. 모델 학습 시 random seed를 고정하는 이유는?
① 재현 가능한 결과 확보 ② 손실 최소화 ③ 학습률 유지 ④ 계산 효율 향상

117. Batch size가 너무 크면?
① 일반화 성능 저하 ② 학습 안정화 ③ 속도 향상 ④ 손실 감소

118. Optimizer 선택 시 가장 중요한 요소는?
① 손실 함수 특성과 데이터 특성 ② 모델 크기 ③ GPU 개수 ④ 학습 횟수

119. Adam과 SGD의 차이는?
① Adam은 적응형 학습률, SGD는 고정 학습률 ② SGD는 확률 기반 ③ Adam은 규칙 기반 ④ 둘 다 동일

120. Validation loss가 증가하는데 training loss는 계속 감소한다면?
① 과적합 발생 ② 데이터 부족 ③ 학습률 너무 낮음 ④ Batch size 오류

121. 정규화(Normalization)의 목적은?
① 모델 안정화 및 수렴 향상 ② 파라미터 감소 ③ 손실 증가 ④ 데이터 크기 증가

122. Weight decay는 어떤 역할을 하는가?
① 가중치 크기 제어로 과적합 방지 ② 학습률 증가 ③ 손실함수 변경 ④ 파라미터 공유

123. 데이터 증강(Data Augmentation)의 목적은?
① 일반화 향상 및 과적합 방지 ② 학습 속도 증가 ③ GPU 효율 개선 ④ 손실 감소

124. Feature engineering의 핵심은?
① 의미 있는 입력 특징 생성 ② 모델 파라미터 수정 ③ 손실함수 변경 ④ 하이퍼튜닝 자동화

125. 모델 평가 시 Test 데이터셋의 목적은?
① 최종 일반화 성능 확인 ② 학습에 참여 ③ 하이퍼튜닝용 ④ 시각화용

126. K-fold 교차검증에서 K를 너무 크게 하면?
① 계산 비용 증가 ② 과적합 증가 ③ 일반화 저하 ④ 데이터 손실

127. 모델 버전 관리에서 중요한 것은?
① 실험 기록과 함께 저장 ② GPU 정보 포함 ③ 실행 시간 단축 ④ 배치 크기 고정

128. Overfitting 탐지 방법은?
① 학습 정확도와 검증 정확도의 차이 관찰 ② GPU 온도 확인 ③ 손실 함수 변경 ④ 샘플 수 조절

129. Hyperparameter tuning 자동화 프레임워크는?
① Optuna ② Flask ③ PyTorch Lightning ④ NumPy

130. Optuna의 주요 탐색 알고리즘은?
① Tree-structured Parzen Estimator (TPE) ② Gradient Descent ③ Random Walk ④ Genetic Search

131. 실험 반복 시 random seed가 다르면?
① 결과 편차 발생 ② 학습속도 향상 ③ 손실 감소 ④ 정확도 고정

132. 모델 평가 시 confusion matrix가 제공하는 정보는?
① 예측과 실제의 분류별 관계 ② 손실 함수 경향 ③ 가중치 변화량 ④ 데이터 편향 정도

133. Precision과 Recall의 trade-off 관계를 조정하는 방법은?
① 임계값(threshold) 변경 ② 모델 크기 변경 ③ 학습률 변경 ④ Dropout 조정

134. ROC 커브의 X축과 Y축은 각각 무엇인가?
① FPR과 TPR ② Recall과 Precision ③ Loss와 Accuracy ④ Precision과 F1

135. 모델 성능 지표 중 F1 Score가 중요한 이유는?
① Precision과 Recall 균형 반영 ② 정확도보다 계산 쉬움 ③ 과적합 지표 ④ 속도 지표

136. Metric이 과적합에 민감하지 않으려면?
① Validation set 기반 계산 ② Train set 기반 계산 ③ Dropout 비활성화 ④ 데이터 증강 제거

137. 실험 중 GPU 자원 효율을 최적화하는 방법은?
① Mixed Precision Training ② Dropout ③ Weight Clipping ④ ReLU 수정

138. Mixed precision training의 장점은?
① 학습 속도 향상과 메모리 절약 ② 손실 감소 ③ 정확도 향상 ④ 데이터 정규화

139. 모델 성능 향상 없이 Validation score 변동이 크다면?
① 데이터 불균형 또는 시드 문제 ② 과적합 ③ 모델 크기 과도 ④ 손실함수 오류

140. 실험 결과 재현이 어렵다면 가장 먼저 확인할 것은?
① 랜덤 시드 및 데이터 순서 ② GPU 수 ③ 손실함수 종류 ④ 옵티마이저

141. 모델 배포 전 성능 검증 단계에서 중요한 것은?
① unseen 데이터 평가 ② 학습 정확도 확인 ③ GPU 온도 모니터링 ④ 시각화

142. 모델 추론(Inference) 시 latency 최적화 방법은?
① Batch 크기 조절 및 TensorRT 활용 ② Dropout 사용 ③ 데이터 정규화 ④ 손실 계산 축소

143. 모델을 여러 환경에서 재현 가능하게 만드는 기술은?
① Docker / Containerization ② GPU 공유 ③ MLflow tracking ④ Script logging

144. 실험에서 reproducibility를 깨뜨리는 요인은?
① 비결정적 연산 및 랜덤성 ② 하이퍼튜닝 고정 ③ seed 설정 ④ 버전 통제

145. ML 파이프라인에서 reproducibility가 중요한 이유는?
① 결과 신뢰성 확보 ② 실행 속도 향상 ③ 학습률 감소 ④ 손실 최소화

146. 실험 자동화(automation)의 이점은?
① 반복 실험 효율화 및 오류 감소 ② 모델 크기 감소 ③ 학습률 고정 ④ Dropout 자동 설정

147. 모델 배포 시 A/B Testing의 목적은?
① 두 버전의 성능 비교 검증 ② GPU 부하 확인 ③ 로그 저장 ④ 하이퍼튜닝 자동화

148. Deployment pipeline에서 rollback이 필요한 이유는?
① 새 모델 성능 저하 시 복귀용 ② 데이터 초기화 ③ 학습 중단 ④ GPU 재시작

149. Continuous Integration/Deployment(CI/CD)와 ML의 결합을 의미하는 용어는?
① MLOps ② DevOps ③ AutoML ④ DataOps

150. MLOps의 주요 목표는?
① 모델 개발·배포 자동화 및 신뢰성 향상 ② 하이퍼튜닝 자동화 ③ GPU 병렬 최적화 ④ 실험 단순화

151. Trustworthy AI의 핵심 목표는?
① 신뢰성 있고 윤리적인 AI 시스템 구축 ② 성능 극대화 ③ 속도 최적화 ④ 데이터 수집 자동화

152. Responsible AI의 3대 원칙 중 하나가 아닌 것은?
① 공정성(Fairness) ② 투명성(Transparency) ③ 무결성(Integrity) ④ 속도(Speed)

153. AI의 공정성(Fairness) 문제를 탐지하는 방법은?
① 성별·인종별 결과 비교 분석 ② GPU 성능 테스트 ③ 손실 함수 관찰 ④ 시드 고정

154. 편향(bias)을 완화하는 가장 직접적인 방법은?
① 데이터 다양화 및 밸런싱 ② 학습률 증가 ③ 모델 축소 ④ Dropout 추가

155. Explainability(설명가능성)의 주요 목적은?
① 모델 결정 과정을 해석하고 신뢰 확보 ② 성능 향상 ③ 속도 증가 ④ 데이터 증강

156. Explainability를 위한 대표적인 도구는?
① LIME, SHAP ② NumPy, Pandas ③ CUDA, cuDNN ④ Flask, FastAPI

157. SHAP 기법의 핵심 원리는?
① 특징(feature)의 기여도를 정량적으로 계산 ② 모델 파라미터를 축소 ③ 데이터 정규화 ④ 시각화 자동화

158. XAI에서 LIME 기법은 무엇을 하는가?
① 입력 변화에 따른 모델 출력의 민감도 분석 ② 모델 크기 축소 ③ GPU 최적화 ④ 데이터 정제

159. Trustworthy AI에서 "Safety"는 무엇을 의미하는가?
① AI가 유해하거나 위험한 출력을 방지하는 것 ② 학습 속도 향상 ③ 데이터 중복 제거 ④ 예측 성능 최대화

160. LLM의 Hallucination 완화 기법이 아닌 것은?
① 데이터셋 검증 강화 ② 외부 지식 소스 연결 ③ 모델 크기 증가 ④ Guardrails 적용

161. Responsible AI에서 Accountability(책임성)은?
① AI 결정에 대한 인간의 책임 보장 ② GPU 자원 관리 ③ 모델 속도 개선 ④ 하이퍼파라미터 제어

162. AI 안전성 검증(Safety Evaluation) 과정의 핵심은?
① 위험한 출력, 편향, 허위 정보 탐지 ② 모델 학습률 평가 ③ 메모리 최적화 ④ 속도 테스트

163. Toxic Output 완화를 위한 일반적 접근은?
① 콘텐츠 필터링 및 정책 제어 ② 데이터 증강 ③ 파라미터 동결 ④ 손실 함수 변경

164. NeMo Guardrails의 주요 역할은?
① 대화형 AI의 안전성과 신뢰성 강화 ② 음성 합성 ③ GPU 자원 관리 ④ 모델 압축

165. Guardrails에서 “flows”는 무엇을 정의하는가?
① 대화 정책과 제어 규칙 ② 하이퍼파라미터 ③ 학습률 스케줄 ④ 시각화 파이프라인

166. Guardrails에서 “rails”는 무엇을 의미하는가?
① 허용/금지되는 응답 행동 규칙 ② 토큰 분리 규칙 ③ 데이터 전처리 함수 ④ GPU 제어 옵션

167. Responsible AI 구현 시 가장 중요한 접근 방식은?
① 정책 기반 제어와 투명성 확보 ② 모델 크기 증가 ③ 속도 최적화 ④ 손실 감소

168. NVIDIA Riva의 주요 활용 분야는?
① 실시간 음성 인식 및 합성 ② 이미지 분류 ③ 시각화 ④ 데이터 병합

169. NVIDIA Triton Server의 장점은?
① 다양한 프레임워크 모델을 통합 배포 ② CPU 전용 최적화 ③ 모델 학습 자동화 ④ 시각화 전용

170. TensorRT의 주요 기능은?
① 추론 속도 향상 및 모델 최적화 ② 데이터셋 병합 ③ 손실함수 수정 ④ 하이퍼튜닝

171. TensorRT 최적화 중 “FP16 모드”의 의미는?
① 반정밀도 연산으로 성능 및 효율 향상 ② 데이터 압축 ③ 학습률 조절 ④ 손실 감소

172. TensorRT에서 “INT8 양자화”의 목적은?
① 모델 크기 축소 및 추론 효율 개선 ② 데이터 정규화 ③ GPU 전력 감소 ④ 정확도 향상

173. NVIDIA Triton과 TensorRT의 공통점은?
① 추론 성능 최적화와 배포 지원 ② 학습 자동화 ③ 데이터 정제 ④ 시각화 기능

174. RAG(Retrieval-Augmented Generation)의 구성 요소가 아닌 것은?
① Retriever ② Generator ③ Scheduler ④ Vector Database

175. RAG 구조의 장점은?
① 최신 지식 참조로 정확도 향상 ② 모델 크기 축소 ③ 파라미터 감소 ④ 데이터 제거

176. Vector Database가 필요한 이유는?
① 유사 문서 검색을 통한 문맥 확장 ② 모델 저장 ③ 파이프라인 병렬화 ④ 토큰 필터링

177. NVIDIA NeMo Toolkit이 지원하는 작업은?
① LLM 구성, 튜닝, 배포 ② 이미지 분류 ③ GPU 클러스터 관리 ④ 데이터 압축

178. NeMo Megatron 모델의 특징은?
① 초대형 LLM 학습을 위한 병렬화 프레임워크 ② 소형 모델 최적화 ③ 비지도 학습용 ④ 음성 모델 전용

179. NeMo가 지원하는 “prompt-tuning”의 장점은?
① 적은 자원으로 도메인 특화 조정 가능 ② 전체 학습 필요 없음 ③ 파라미터 효율 높음 ④ 모두 해당

180. NVIDIA Riva에서 TTS(Text-to-Speech) 모델의 역할은?
① 텍스트를 음성으로 변환 ② 음성을 텍스트로 변환 ③ 데이터 정규화 ④ 모델 최적화

181. Responsible AI의 구현에서 “Transparency”는?
① 모델의 의사결정 과정을 설명 가능하게 함 ② 성능 향상 ③ 데이터 암호화 ④ 속도 개선

182. “Privacy Preservation”의 핵심 기술은?
① Differential Privacy ② Data Augmentation ③ Dropout ④ Batch Normalization

183. Differential Privacy의 목적은?
① 개인 데이터 보호와 통계적 노이즈 추가 ② 속도 향상 ③ 손실 최소화 ④ 데이터 정규화

184. Explainable AI가 필요한 이유는?
① 인간이 AI 결정을 이해하고 신뢰할 수 있도록 함 ② 모델 압축 ③ 속도 향상 ④ 정확도 증가

185. Fairness 평가 시 사용되는 방법 중 하나는?
① 그룹별 성능 차이 분석 ② Dropout 비율 변경 ③ GPU 사용량 비교 ④ 손실 감소율 측정

186. AI 모델이 잘못된 결정을 내렸을 때 필요한 조치는?
① Error analysis 및 재학습 ② 학습률 증가 ③ 손실 함수 수정 ④ 데이터 축소

187. Ethical AI가 고려해야 할 요소는?
① 투명성, 공정성, 책임성 ② 속도, 정확도, 비용 ③ GPU, 메모리, 전력 ④ 손실, 정규화, 편향

188. RAG 구조에서 Retriever의 역할은?
① 외부 지식에서 관련 문서 검색 ② 답변 생성 ③ 모델 평가 ④ 데이터 정규화

189. NeMo Framework와 HuggingFace의 차이는?
① NeMo는 NVIDIA 생태계 통합용, HuggingFace는 범용 모델 허브 ② 둘 다 동일 기능 ③ NeMo는 시각화 전용 ④ HuggingFace는 상용 전용

190. Triton Server의 “Dynamic Batching” 기능은?
① 요청을 자동 병합해 처리 효율 향상 ② 학습률 자동 조절 ③ 모델 전환 ④ 메모리 정규화

191. TensorRT Engine의 목적은?
① GPU에서 최적화된 실행 그래프 생성 ② 학습 데이터 저장 ③ 하이퍼파라미터 튜닝 ④ 시각화 제공

192. NeMo의 Training Configuration에서 YAML 사용 이유는?
① 구성 재현성 및 설정 관리 용이 ② 데이터 시각화 ③ 학습률 증가 ④ 하이퍼파라미터 감소

193. Responsible AI 구현 시 가장 어려운 문제 중 하나는?
① 편향 탐지와 완화의 객관성 확보 ② 속도 조절 ③ GPU 병목 ④ 데이터 저장소 변경

194. Trustworthy AI 개발 시 고려해야 할 최종 목표는?
① 사회적 신뢰와 안전성 확보 ② 추론 속도 향상 ③ 모델 경량화 ④ 하이퍼튜닝 자동화

195. Fairness 문제를 해결하기 위한 기술적 접근은?
① Re-sampling, Debiasing, Regularization ② Dropout ③ FP16 ④ LayerNorm

196. Toxic content 탐지를 위한 필터링 방식은?
① 분류 모델 기반 콘텐츠 검출 ② 데이터 압축 ③ 하이퍼튜닝 ④ 샘플링

197. Hallucination 감축을 위해 자주 사용되는 접근은?
① RAG와 외부 지식 베이스 결합 ② 데이터 감소 ③ 모델 축소 ④ Dropout

198. Responsible AI에서 “Robustness”는 무엇을 뜻하는가?
① 입력 변화에 강한 일관된 성능 ② 빠른 추론 속도 ③ GPU 효율 ④ 정확도 향상

199. Trustworthy AI의 핵심 평가 항목으로 옳지 않은 것은?
① 모델 크기 ② 공정성 ③ 안전성 ④ 설명가능성

200. NVIDIA 생태계에서 Generative AI 솔루션을 통합하는 전략은?
① NeMo + TensorRT + Triton + Guardrails 결합 ② PyTorch 단독 사용 ③ Riva 단독 사용 ④ HuggingFace 단독 실행

201. NVIDIA Triton Inference Server에서 Model Repository의 역할은?
① 여러 모델을 버전별로 관리 및 배포 ② 데이터셋 저장 ③ 로그 기록 전용 ④ GPU 모니터링

202. Triton의 Ensemble 모델 기능은 무엇을 가능하게 하는가?
① 여러 모델을 파이프라인 형태로 연결한 추론 수행 ② 모델 병합 후 단일 추론 ③ 하이퍼튜닝 자동화 ④ 데이터 증강

203. TensorRT에서 Layer Fusion의 효과는?
① 연산 병합으로 추론 속도 향상 ② 모델 정확도 향상 ③ 데이터 손실 감소 ④ 메모리 증가

204. TensorRT의 Calibration 과정은 어떤 용도로 사용되는가?
① 양자화(Quantization) 시 정밀도 보정 ② 학습률 조정 ③ 손실함수 최적화 ④ 하이퍼파라미터 탐색

205. CUDA Stream을 활용하는 이유는?
① GPU 연산 병렬 실행 ② 데이터 압축 ③ 모델 크기 축소 ④ 손실 제어

206. cuDNN의 주요 역할은?
① GPU 가속을 위한 딥러닝 연산 최적화 ② 데이터 전처리 ③ 시각화 ④ 하이퍼튜닝

207. NVIDIA NeMo Megatron의 병렬화 전략 중 “Tensor Model Parallelism”이란?
① 모델의 가중치를 여러 GPU에 분산 계산 ② 데이터 샘플 분할 ③ 하이퍼파라미터 동기화 ④ 배치 분할

208. NeMo Megatron의 Pipeline Parallelism은 무엇을 의미하는가?
① 모델의 레이어를 여러 GPU에 분할하여 순차 처리 ② 학습률 자동 조절 ③ 메모리 공유 ④ 데이터 로더 최적화

209. Mixed Precision Training 시 FP16과 FP32를 혼합 사용하는 이유는?
① 연산 속도와 정확도 균형 확보 ② GPU 발열 감소 ③ 모델 크기 감소 ④ 학습률 증가

210. TensorRT에서 “Kernel Auto-Tuning”이 수행하는 일은?
① 최적의 GPU 커널 선택으로 실행 효율 극대화 ② 손실 최소화 ③ 데이터 증강 ④ 파라미터 초기화

211. NeMo Guardrails의 “config.yaml”에서 policy 설정의 역할은?
① 대화 제한 규칙 및 허용 응답 제어 ② 학습률 설정 ③ 데이터 경로 지정 ④ GPU 사용량 제한

212. RAG 시스템의 Retriever 단계에서 Vector Index의 역할은?
① 유사도 기반 빠른 검색 수행 ② 학습률 조정 ③ 데이터 증강 ④ 파이프라인 병합

213. RAG에서 Generator가 Retriever의 결과를 활용하는 방식은?
① 검색된 문서를 context로 활용해 답변 생성 ② 검색 결과 필터링 ③ 파라미터 조정 ④ 벡터 업데이트

214. NVIDIA AI Foundation Models의 목적은?
① 대규모 사전학습 모델을 API 형태로 제공 ② 데이터 라벨링 ③ 모델 압축 ④ GPU 제어

215. NVIDIA AI Workbench의 기능은?
① 로컬–클라우드 통합 개발 및 실험 환경 제공 ② 하드웨어 관리 ③ 이미지 렌더링 ④ 데이터베이스 관리

