1. Transformer의 핵심 구조적 특징은 무엇인가?
① Attention Mechanism ② Gradient Clipping ③ Recurrent Loop ④ Convolution Layer

2. Self-Attention의 주요 목적은?
① 모델 복잡도 감소 ② 입력 간 관계 파악 ③ 손실 최소화 ④ 파라미터 수 감소

3. LLM의 입력 단위인 토큰(Token)의 의미는?
① 문장 단위 ② 문서 전체 ③ 단어 또는 단어 조각 ④ 문단

4. Fine-tuning의 주요 목적은?
① 모델 파라미터 감소 ② 새로운 모델 구조 설계 ③ 데이터 전처리 효율화 ④ 특정 도메인에 모델 적응

5. Prompt-tuning과 Fine-tuning의 차이는?
① Prompt-tuning은 소수 파라미터만 조정 ② Fine-tuning은 임베딩만 수정 ③ Prompt-tuning은 전체 파라미터 수정 ④ Fine-tuning은 입력문 수정

6. Transformer의 Encoder가 주로 하는 일은?
① 텍스트 생성 ② 입력 문맥 인코딩 ③ 확률 계산 ④ 모델 평가

7. Transformer의 Decoder의 역할은?
① 입력 특징 추출 ② 토큰화 수행 ③ 문장 생성 ④ 모델 학습 가속

8. Attention Score 계산에 사용되는 세 요소는?
① Token, Layer, Bias ② Input, Output, Weight ③ Node, Edge, Weight ④ Query, Key, Value

9. LLM의 컨텍스트 윈도우(Context Window)는?
① 입력 가능한 최대 토큰 길이 ② 학습률 ③ 모델 학습 속도 ④ 배치 크기

10. Embedding의 주요 목적은?
① 데이터 정규화 ② 텍스트를 수치 벡터로 표현 ③ 손실 보정 ④ 모델 크기 축소

11. RAG(Retrieval-Augmented Generation)의 핵심 아이디어는?
① 미세조정 자동화 ② 생성 속도 향상 ③ 생성 모델에 외부 검색 결합 ④ 모델 경량화

12. Vector Database의 주된 역할은?
① 관계형 데이터 쿼리 ② 모델 가중치 저장 ③ 데이터베이스 정규화 ④ 벡터 기반 유사도 검색

13. LLM 응답의 일관성 향상을 위한 기술은?
① Beam Search ② Gradient Clipping ③ Batch Normalization ④ Weight Decay

14. LLM의 할루시네이션(Hallucination) 완화 방법은?
① 학습률 증가 ② 외부 지식 소스 참조 ③ 무작위 토큰 삽입 ④ 드롭아웃 제거

15. NeMo Framework의 주요 목적은?
① GPU 클러스터 관리 ② 데이터 압축 ③ 대형 언어 모델 구축·튜닝 지원 ④ 시각화 도구 제공

16. Triton Inference Server의 기능은?
① GPU 전력 관리 ② 하이퍼파라미터 최적화 ③ 데이터셋 라벨링 ④ 모델 배포 및 추론 서비스 제공

17. TensorRT의 주된 용도는?
① 추론 속도 최적화 ② 모델 학습 자동화 ③ 데이터 전처리 ④ 오디오 변환

18. NVIDIA의 Riva는 주로 어떤 기능에 사용되는가?
① 이미지 변환 ② 음성 인식·합성 ③ 데이터베이스 관리 ④ 시각적 객체 탐지

19. Python에서 LLM API 호출 시 일반적으로 사용하는 방식은?
① SQL Query ② Socket Stream ③ REST API ④ FTP Request

20. PyTorch의 기본 구성 요소 중 텐서(Tensor)는 무엇인가?
① 파이썬 함수 ② 손실 함수 ③ 모델 구조체 ④ 다차원 배열 구조

21. 학습 데이터와 검증 데이터를 구분하는 이유는?
① 오버피팅 방지 및 일반화 검증 ② 손실 계산 단순화 ③ 메모리 절약 ④ 학습 속도 향상

22. 과적합(Overfitting)을 방지하기 위한 방법은?
① Epoch 수 증가 ② Dropout 사용 ③ Learning Rate 증가 ④ Batch Size 감소

23. 하이퍼파라미터 튜닝의 주 목적은?
① 모델 구조 변경 ② 데이터 증강 ③ 최적 성능 조합 탐색 ④ 손실함수 변경

24. 성능 평가 지표 중 정밀도(Precision)는?
① 오차 제곱 평균 ② 재현율과 동일 ③ 예측 중 실제 양성의 비율 ④ 실제 양성 중 예측된 양성의 비율

25. F1 Score는 어떤 두 지표의 조화평균인가?
① Precision과 Recall ② 손실과 학습률 ③ Precision과 Accuracy ④ 정확도와 손실

26. 지도학습(Supervised Learning)의 특징은?
① 레이블 불필요 ② 라벨 데이터 사용 ③ 강화학습 기반 ④ 비지도 데이터 사용

27. 비지도학습(Unsupervised Learning)의 목적은?
① 보상 최대화 ② 피드백 기반 학습 ③ 데이터 구조 파악 ④ 예측 정확도 향상

28. 강화학습(Reinforcement Learning)의 핵심 개념은?
① 회귀분석 ② 클러스터링 ③ 비지도 학습 ④ 보상 기반 학습

29. 손실 함수(Loss Function)의 역할은?
① 모델의 오류 측정 ② GPU 메모리 관리 ③ 학습률 계산 ④ 모델 크기 조정

30. 실험 관리 도구 MLflow의 기능은?
① 하이퍼파라미터 자동 튜닝 ② 실험 추적 및 버전 관리 ③ 데이터 시각화 전용 ④ API 통합

31. 데이터 전처리 과정에서 결측값 처리는?
① 무시 ② 무작위 변경 ③ 제거 또는 대체 ④ 정규화로 해결

32. 데이터 스케일링의 목적은?
① 시각화 개선 ② 손실 계산 가속 ③ 샘플 수 증가 ④ 모델 입력 균형 맞추기

33. Pandas의 주요 역할은?
① 데이터 분석과 조작 ② 신경망 구성 ③ 모델 평가 ④ 시각화

34. Matplotlib은 주로 어떤 용도로 사용되는가?
① 하이퍼튜닝 ② 시각화 ③ 데이터 변환 ④ 벡터 연산

35. Explainable AI(XAI)의 목적은?
① 데이터 증강 ② 성능 최대화 ③ 모델 의사결정 해석 가능성 향상 ④ 모델 압축

36. 공정성(Fairness) 확보의 핵심은?
① 정밀도 향상 ② 계산 효율화 ③ 속도 최적화 ④ 편향 최소화

37. LLM 응답의 안전성(Safety) 강화를 위한 방법은?
① 콘텐츠 필터링 및 정책 설정 ② 모델 압축 ③ 학습률 감소 ④ 입력 샘플링

38. AI 편향(Bias)의 주요 원인은?
① 모델 크기 ② 불균형 데이터 ③ 드롭아웃 설정 ④ GPU 성능 부족

39. Responsible AI가 중시하는 요소는?
① 오차·잡음·편향 ② 정확도·정밀도·재현율 ③ 공정성·투명성·책임성 ④ 성능·속도·비용

40. Explainability를 향상시키는 기법은?
① Dropout ② PCA ③ Adam Optimizer ④ LIME, SHAP

41. NVIDIA NeMo Guardrails의 역할은?
① 대화형 AI의 안전성과 제어 ② GPU 성능 향상 ③ 음성 합성 ④ 데이터 병렬 처리

42. 모델 재현성(Reproducibility)을 확보하기 위한 조치는?
① 하이퍼튜닝 자동화 ② 시드 고정 및 버전 관리 ③ 데이터 증강 ④ 랜덤성 증가

43. 모델 성능 비교 시 공정성을 위해 필요한 것은?
① 임의 배치 ② GPU 동일 모델 ③ 동일한 평가 데이터 ④ 코드 난수화

44. Python에서 API 요청 시 자주 사용하는 라이브러리는?
① pandas ② matplotlib ③ numpy ④ requests

45. LLM 기반 서비스에서 RAG 구조의 장점은?
① 최신 정보 반영 가능 ② 학습 데이터 감소 ③ 토큰 절약 ④ 모델 크기 축소

46. LLM의 출력 확률을 조절하는 temperature 값이 높을수록?
① 일관성 증가 ② 무작위성 증가 ③ 출력 길이 감소 ④ 결정적 응답

47. 모델 평가 지표 중 Recall은?
① 손실 최소화율 ② 예측 음성 중 실제 음성 비율 ③ 실제 양성 중 예측 양성 비율 ④ F1 Score와 동일

48. GPU 병렬처리가 유리한 이유는?
① RAM 속도 빠름 ② CPU보다 전력 소모 적음 ③ 저장공간 많음 ④ 대량 행렬 연산 병렬화 가능

49. LLM 개발 시 토큰화(tokenization)의 역할은?
① 텍스트를 모델 입력 단위로 분리 ② 손실 계산 ③ GPU 초기화 ④ 모델을 저장

50. Generative AI의 대표적 응용 분야는?
① 데이터베이스 관리 ② 텍스트·이미지·음성 생성 ③ 모델 평가 ④ 코드 압축

51. Large Language Model(LLM)에서 Fine-tuning의 주요 이점은?
① 모델 크기 축소 ② 파라미터 감소 ③ 특정 도메인에 모델 적응 ④ 학습 데이터 자동 생성

52. Transformer의 Attention Mechanism에서 Query-Key 유사도는 어떤 값으로 계산되는가?
① 행렬식 ② 거리 기반 함수 ③ 평균값 ④ 점곱(dot product)

53. Layer Normalization의 목적은?
① 학습 안정화 및 수렴 향상 ② 모델 크기 감소 ③ 손실 보정 ④ 데이터 스케일 조정

54. Positional Encoding은 어떤 역할을 하는가?
① 토큰 분리 ② 단어 순서 정보 추가 ③ 벡터 크기 축소 ④ 손실 감소

55. LLM에서 Parameter 수가 많을수록 일반적으로 기대되는 효과는?
① 학습 속도 향상 ② 메모리 절약 ③ 표현력 향상 ④ 추론 속도 향상

56. Attention의 Softmax 단계는 어떤 역할을 하는가?
① Dropout 적용 ② ReLU 활성화 ③ 손실 최소화 ④ 가중치 정규화

57. Encoder-Decoder 구조의 대표적 응용은?
① 번역기 ② 회귀 분석 ③ 이미지 분류기 ④ 추천 시스템

58. HuggingFace Transformers 라이브러리의 주요 기능은?
① GPU 제어 ② 사전 학습된 모델 불러오기 및 파인튜닝 ③ 시각화 도구 제공 ④ 데이터 증강

59. Prompt Engineering의 주요 목적은?
① 학습률 조정 ② GPU 효율 향상 ③ 모델 응답 품질 향상 ④ 토큰화 가속

60. Temperature 하이퍼파라미터가 낮을 때 LLM의 출력 특징은?
① 불안정 출력 ② 무작위성 증가 ③ 창의적 응답 증가 ④ 결정적이고 일관된 응답

61. Top-k 샘플링은 어떤 기법인가?
① 확률이 높은 상위 k개 토큰만 선택 ② 학습률 k배 증가 ③ k개 문장 병합 ④ 손실 상위 k개 필터 제거

62. Top-p(=Nucleus) 샘플링은?
① k개 확률 평균화 ② 누적 확률이 p 이하인 토큰 집합에서 샘플링 ③ 확률 최대값 선택 ④ p개의 문장 분리

63. Tokenization 과정의 주된 목표는?
① 확률 계산 ② 데이터 정규화 ③ 텍스트를 모델이 이해할 수 있는 단위로 분할 ④ 모델 학습률 조절

64. Subword 토크나이징의 장점은?
① 문장 길이 고정 ② 계산 속도 향상 ③ 손실 함수 단순화 ④ 희귀 단어 처리 유연성

65. 모델의 Generalization을 높이려면?
① 다양한 데이터와 적절한 정규화 ② Epoch 증가 ③ Dropout 제거 ④ 손실 가중치 감소

66. Batch Normalization의 효과는?
① 손실 최소화 ② 학습 안정화 및 속도 향상 ③ 파라미터 감소 ④ 모델 단순화

67. Activation Function 중 ReLU의 주요 장점은?
① 학습률 향상 ② 계산량 감소 ③ Gradient 소실 완화 ④ 손실 제어

68. Cross-Entropy Loss는 주로 어떤 문제에 사용되는가?
① 회귀 문제 ② 강화학습 ③ 클러스터링 ④ 분류 문제

69. 학습률(Learning Rate)이 너무 높으면?
① 발산(unstable) ② 정확도 향상 ③ 손실 최소화 ④ 수렴 빠름

70. Optimizer 중 Adam의 특징은?
① 고정 학습률 사용 ② Adaptive 학습률과 모멘텀 결합 ③ 가중치 정규화 ④ 확률적 손실 추정

71. Dropout의 목적은?
① 학습 속도 향상 ② 파라미터 증가 ③ 과적합 방지 ④ 손실 감소

72. Early Stopping의 역할은?
① 데이터 증강 제한 ② GPU 과열 방지 ③ 학습률 고정 ④ 과적합 방지를 위해 학습 조기 종료

73. Gradient Vanishing 문제를 완화하기 위한 방법은?
① ReLU 사용 ② 학습률 감소 ③ 손실 증가 ④ Dropout 제거

74. 하이퍼파라미터 탐색 자동화 도구로 유명한 것은?
① Numpy ② Optuna ③ PyTorch Lightning ④ Matplotlib

75. RAG 시스템에서 검색 단계는 주로 무엇을 수행하는가?
① 토큰화 수행 ② 모델 응답 생성 ③ 외부 문서에서 관련 정보 벡터 검색 ④ 텍스트 정규화

76. LLM의 응답에서 맥락 유지 향상을 위해 사용하는 구조는?
① ReLU ② Dropout ③ Convolution ④ Attention

77. LLM의 학습에서 Fine-tuning과 In-context Learning의 차이는?
① Fine-tuning은 파라미터 업데이트, In-context는 입력 기반 적응 ② 둘 다 파라미터 조정

78. 데이터셋 분할 시 일반적인 비율은?
① train 50%, test 50% ② train 80%, val 10%, test 10% ③ train 70%, val 30% ④ train 90%, test 10%

79. Cross-validation의 목적은?
① 배치 사이즈 설정 ② GPU 최적화 ③ 데이터 의존성 완화 및 일반화 성능 검증 ④ 학습률 조정

80. ROC 곡선에서 AUC 값이 의미하는 것은?
① 손실 변화율 ② 데이터 크기 ③ 정규화 정도 ④ 분류기의 전체 성능

81. Precision-Recall 곡선은 어떤 데이터셋에 더 적합한가?
① 불균형 데이터셋 ② 균형 데이터셋 ③ 시계열 데이터 ④ 잡음 많은 데이터

82. Outlier(이상치)를 처리하는 방법으로 옳은 것은?
① 데이터 병합 ② 제거하거나 변환 ③ 학습률 조정 ④ 무시

83. Feature Scaling 기법 중 StandardScaler는?
① 원-핫 인코딩 ② 0~1 정규화 ③ 평균 0, 분산 1로 변환 ④ 로그 스케일 변환

84. Pandas의 DataFrame은 무엇인가?
① 벡터 ② 텍스트 파일 포맷 ③ 그래프 구조 ④ 2차원 테이블 형태의 데이터 구조

85. Matplotlib에서 plt.plot()의 기본 용도는?
① 선 그래프 그리기 ② 막대 그래프 ③ 히스토그램 ④ 산점도

86. AI 모델의 Explainability를 높이기 위한 프레임워크는?
① Triton, TensorRT ② SHAP, LIME ③ NumPy, Pandas ④ CUDA, cuDNN

87. Responsible AI에서 ‘투명성(Transparency)’이란?
① GPU 자원 공개 ② 코드 오픈소스화 ③ 모델 의사결정 과정을 설명할 수 있음 ④ 데이터 암호화

88. Trustworthy AI가 강조하는 세 가지 핵심 요소는?
① 비용, 품질, 성능 ② 가용성, 투명성, 병렬성 ③ 속도, 효율, 정확도 ④ 공정성, 안전성, 설명가능성

89. LLM의 할루시네이션 문제는 주로 어떤 원인인가?
① 사실 정보 부족 ② 모델 크기 과도 ③ 토큰화 오류 ④ 학습률 과소

90. NeMo Guardrails의 주된 사용 목적은?
① GPU 성능 개선 ② LLM 응답 안전성 강화 ③ 모델 경량화 ④ 음성 합성

91. NVIDIA Triton이 제공하는 주요 기능은?
① 시각화 ② 데이터 증강 ③ 모델 추론 서비스 ④ 학습 파이프라인 생성

92. TensorRT의 최적화 방식 중 하나는?
① 손실 가중치 조정 ② 배치 샘플링 ③ 데이터 정규화 ④ 연산 그래프 병합 및 양자화

93. NeMo Toolkit의 구성 요소로 옳은 것은?
① 모델 구성, 학습, 배포 지원 ② GPU 모니터링 ③ 이미지 증강 ④ 네트워크 관리

94. LLM 실험 관리에 사용되는 대표 오픈소스는?
① Optuna, cuDNN ② MLflow, Weights & Biases ③ Keras, Flask ④ TensorBoard, CUDA

95. 데이터 편향(bias)을 줄이기 위한 방법은?
① 학습률 증가 ② Dropout 추가 ③ 데이터 다양성 확보 및 밸런싱 ④ 모델 크기 축소

96. LLM에서 "context length"가 긴 모델의 장점은?
① 추론 속도 향상 ② 학습률 증가 ③ 파라미터 감소 ④ 더 긴 대화 맥락 이해 가능

97. Prompt-tuning의 장점은?
① 적은 파라미터로 빠른 적응 ② 모든 가중치 수정 ③ 대규모 학습 필요 ④ 모델 구조 변경

98. GPU 가속의 핵심 원리는?
① 데이터 압축 ② 병렬 연산을 통한 처리 속도 향상 ③ CPU 제어 완화 ④ 토큰 수 감소

99. Fine-tuning 데이터셋의 품질이 낮을 경우?
① 일반화 향상 ② 메모리 감소 ③ 모델 성능 저하 및 편향 증가 ④ 속도 증가

100. Responsible AI의 궁극적 목표는?
① 처리속도 향상 ② 사용자 데이터 수집 ③ 모델 크기 축소 ④ 신뢰할 수 있고 윤리적인 AI 구축

101. 실험 재현성(Reproducibility)을 확보하기 위해 필요한 조치는?
① 시드 고정 및 버전 관리 ② 데이터 증강 ③ 무작위 초기화 ④ 하이퍼튜닝 자동화

102. 모델 학습 실험에서 하이퍼파라미터 튜닝의 주요 목적은?
① 학습 데이터 축소 ② 최적 성능 조합 탐색 ③ 오버피팅 유도 ④ 모델 구조 단순화

103. Cross-validation을 사용하는 이유는?
① GPU 효율 증가 ② 학습 속도 향상 ③ 일반화 성능 검증 및 데이터 편향 완화 ④ 손실 최소화

104. Early stopping이 과적합을 줄이는 이유는?
① 파라미터 동결 ② 데이터 증강 중단 ③ 학습률 감소 ④ 검증 손실 증가 시 학습 중단

105. Learning rate scheduler의 역할은?
① 학습 진행에 따라 학습률 조정 ② 모델 크기 조절 ③ 배치 크기 고정 ④ Dropout 조절

106. 실험 로깅(logging)이 중요한 이유는?
① 모델 구조 단순화 ② 결과 추적 및 재현 가능성 확보 ③ 파라미터 감소 ④ GPU 메모리 절약

107. MLflow의 주요 기능은?
① 하이퍼튜닝 자동화 ② 시각화 전용 ③ 실험 기록 및 모델 버전 관리 ④ 데이터 정규화

108. Weights & Biases(W&B)의 주요 장점은?
① GPU 가속 지원 ② 자동 데이터 정제 ③ 모델 양자화 ④ 실험 추적, 시각화, 협업 기능 제공

109. 실험 관리 도구의 공통 목적은?
① 재현성 확보와 성능 비교 용이 ② 모델 저장 용량 감소 ③ 코드 압축 ④ 학습률 자동화

110. Grid Search의 단점은?
① 정확도 낮음 ② 계산 비용 높음 ③ 무작위성 증가 ④ 탐색 불가능

111. Random Search의 장점은?
① 계산량 최소 ② 재현성 향상 ③ 효율적 탐색 가능 ④ 완전 탐색

112. Bayesian Optimization의 특징은?
① 무작위 시도 ② 모든 조합 탐색 ③ 규칙 기반 탐색 ④ 확률 모델을 사용해 효율적 탐색

113. 하이퍼파라미터 탐색 시 성능 비교 기준으로 사용하는 지표는?
① Validation score ② 파라미터 수 ③ Training loss ④ Gradient 평균

114. 실험 결과를 정량적으로 비교하려면?
① 모델 구조 변경 ② 공통 데이터셋과 지표 사용 ③ 학습률 변경 ④ 임의 샘플링

115. Reproducibility 확보를 위해 로그에 기록해야 할 항목은?
① 모델 크기만 ② 코드 실행 시간만 ③ 하이퍼파라미터, 데이터 버전, 코드 커밋 ④ GPU 전력소모

116. 모델 학습 시 random seed를 고정하는 이유는?
① 손실 최소화 ② 계산 효율 향상 ③ 학습률 유지 ④ 재현 가능한 결과 확보

117. Batch size가 너무 크면?
① 일반화 성능 저하 ② 손실 감소 ③ 학습 안정화 ④ 속도 향상

118. Optimizer 선택 시 가장 중요한 요소는?
① 모델 크기 ② 손실 함수 특성과 데이터 특성 ③ GPU 개수 ④ 학습 횟수

119. Adam과 SGD의 차이는?
① Adam은 규칙 기반 ② SGD는 확률 기반 ③ Adam은 적응형 학습률, SGD는 고정 학습률 ④ 둘 다 동일

120. Validation loss가 증가하는데 training loss는 계속 감소한다면?
① 데이터 부족 ② Batch size 오류 ③ 학습률 너무 낮음 ④ 과적합 발생

121. 정규화(Normalization)의 목적은?
① 모델 안정화 및 수렴 향상 ② 데이터 크기 증가 ③ 파라미터 감소 ④ 손실 증가

122. Weight decay는 어떤 역할을 하는가?
① 학습률 증가 ② 가중치 크기 제어로 과적합 방지 ③ 파라미터 공유 ④ 손실함수 변경

123. 데이터 증강(Data Augmentation)의 목적은?
① 학습 속도 증가 ② GPU 효율 개선 ③ 일반화 향상 및 과적합 방지 ④ 손실 감소

124. Feature engineering의 핵심은?
① 모델 파라미터 수정 ② 손실함수 변경 ③ 하이퍼튜닝 자동화 ④ 의미 있는 입력 특징 생성

125. 모델 평가 시 Test 데이터셋의 목적은?
① 최종 일반화 성능 확인 ② 하이퍼튜닝용 ③ 시각화용 ④ 학습에 참여

126. K-fold 교차검증에서 K를 너무 크게 하면?
① 과적합 증가 ② 계산 비용 증가 ③ 일반화 저하 ④ 데이터 손실

127. 모델 버전 관리에서 중요한 것은?
① 배치 크기 고정 ② GPU 정보 포함 ③ 실험 기록과 함께 저장 ④ 실행 시간 단축

128. Overfitting 탐지 방법은?
① 샘플 수 조절 ② GPU 온도 확인 ③ 손실 함수 변경 ④ 학습 정확도와 검증 정확도의 차이 관찰

129. Hyperparameter tuning 자동화 프레임워크는?
① Optuna ② PyTorch Lightning ③ Flask ④ NumPy

130. Optuna의 주요 탐색 알고리즘은?
① Random Walk ② Tree-structured Parzen Estimator (TPE) ③ Gradient Descent ④ Genetic Search

131. 실험 반복 시 random seed가 다르면?
① 손실 감소 ② 정확도 고정 ③ 결과 편차 발생 ④ 학습속도 향상

132. 모델 평가 시 confusion matrix가 제공하는 정보는?
① 손실 함수 경향 ② 가중치 변화량 ③ 데이터 편향 정도 ④ 예측과 실제의 분류별 관계

133. Precision과 Recall의 trade-off 관계를 조정하는 방법은?
① 임계값(threshold) 변경 ② Dropout 조정 ③ 학습률 변경 ④ 모델 크기 변경

134. ROC 커브의 X축과 Y축은 각각 무엇인가?
① Loss와 Accuracy ② FPR과 TPR ③ Recall과 Precision ④ Precision과 F1

135. 모델 성능 지표 중 F1 Score가 중요한 이유는?
① 정확도보다 계산 쉬움 ② 속도 지표 ③ Precision과 Recall 균형 반영 ④ 과적합 지표

136. Metric이 과적합에 민감하지 않으려면?
① 데이터 증강 제거 ② Dropout 비활성화 ③ Train set 기반 계산 ④ Validation set 기반 계산

137. 실험 중 GPU 자원 효율을 최적화하는 방법은?
① Mixed Precision Training ② Weight Clipping ③ ReLU 수정 ④ Dropout

138. Mixed precision training의 장점은?
① 데이터 정규화 ② 학습 속도 향상과 메모리 절약 ③ 손실 감소 ④ 정확도 향상

139. 모델 성능 향상 없이 Validation score 변동이 크다면?
① 손실함수 오류 ② 과적합 ③ 데이터 불균형 또는 시드 문제 ④ 모델 크기 과도

140. 실험 결과 재현이 어렵다면 가장 먼저 확인할 것은?
① GPU 수 ② 옵티마이저 ③ 손실함수 종류 ④ 랜덤 시드 및 데이터 순서

141. 모델 배포 전 성능 검증 단계에서 중요한 것은?
① unseen 데이터 평가 ② GPU 온도 모니터링 ③ 시각화 ④ 학습 정확도 확인

142. 모델 추론(Inference) 시 latency 최적화 방법은?
① 손실 계산 축소 ② Batch 크기 조절 및 TensorRT 활용 ③ 데이터 정규화 ④ Dropout 사용

143. 모델을 여러 환경에서 재현 가능하게 만드는 기술은?
① MLflow tracking ② Script logging ③ Docker / Containerization ④ GPU 공유

144. 실험에서 reproducibility를 깨뜨리는 요인은?
① 하이퍼튜닝 고정 ② seed 설정 ③ 버전 통제 ④ 비결정적 연산 및 랜덤성

145. ML 파이프라인에서 reproducibility가 중요한 이유는?
① 결과 신뢰성 확보 ② 학습률 감소 ③ 손실 최소화 ④ 실행 속도 향상

146. 실험 자동화(automation)의 이점은?
① 학습률 고정 ② 반복 실험 효율화 및 오류 감소 ③ Dropout 자동 설정 ④ 모델 크기 감소

147. 모델 배포 시 A/B Testing의 목적은?
① 로그 저장 ② 하이퍼튜닝 자동화 ③ 두 버전의 성능 비교 검증 ④ GPU 부하 확인

148. Deployment pipeline에서 rollback이 필요한 이유는?
① GPU 재시작 ② 데이터 초기화 ③ 학습 중단 ④ 새 모델 성능 저하 시 복귀용

149. Continuous Integration/Deployment(CI/CD)와 ML의 결합을 의미하는 용어는?
① MLOps ② DevOps ③ AutoML ④ DataOps

150. MLOps의 주요 목표는?
① GPU 병렬 최적화 ② 모델 개발·배포 자동화 및 신뢰성 향상 ③ 실험 단순화 ④ 하이퍼튜닝 자동화

151. Trustworthy AI의 핵심 목표는?
① 성능 극대화 ② 데이터 수집 자동화 ③ 신뢰성 있고 윤리적인 AI 시스템 구축 ④ 속도 최적화

152. Responsible AI의 3대 원칙 중 하나가 아닌 것은?
① 투명성(Transparency) ② 공정성(Fairness) ③ 무결성(Integrity) ④ 속도(Speed)

153. AI의 공정성(Fairness) 문제를 탐지하는 방법은?
① 성별·인종별 결과 비교 분석 ② GPU 성능 테스트 ③ 시드 고정 ④ 손실 함수 관찰

154. 편향(bias)을 완화하는 가장 직접적인 방법은?
① 모델 축소 ② 데이터 다양화 및 밸런싱 ③ Dropout 추가 ④ 학습률 증가

155. Explainability(설명가능성)의 주요 목적은?
① 속도 증가 ② 데이터 증강 ③ 모델 결정 과정을 해석하고 신뢰 확보 ④ 성능 향상

156. Explainability를 위한 대표적인 도구는?
① NumPy, Pandas ② CUDA, cuDNN ③ Flask, FastAPI ④ LIME, SHAP

157. SHAP 기법의 핵심 원리는?
① 특징(feature)의 기여도를 정량적으로 계산 ② 시각화 자동화 ③ 모델 파라미터를 축소 ④ 데이터 정규화

158. XAI에서 LIME 기법은 무엇을 하는가?
① 모델 크기 축소 ② 입력 변화에 따른 모델 출력의 민감도 분석 ③ GPU 최적화 ④ 데이터 정제

159. Trustworthy AI에서 "Safety"는 무엇을 의미하는가?
① 예측 성능 최대화 ② 학습 속도 향상 ③ AI가 유해하거나 위험한 출력을 방지하는 것 ④ 데이터 중복 제거

160. LLM의 Hallucination 완화 기법이 아닌 것은?
① 외부 지식 소스 연결 ② Guardrails 적용 ③ 데이터셋 검증 강화 ④ 모델 크기 증가

161. Responsible AI에서 Accountability(책임성)은?
① AI 결정에 대한 인간의 책임 보장 ② 하이퍼파라미터 제어 ③ 모델 속도 개선 ④ GPU 자원 관리

162. AI 안전성 검증(Safety Evaluation) 과정의 핵심은?
① 속도 테스트 ② 위험한 출력, 편향, 허위 정보 탐지 ③ 모델 학습률 평가 ④ 메모리 최적화

163. Toxic Output 완화를 위한 일반적 접근은?
① 손실 함수 변경 ② 데이터 증강 ③ 콘텐츠 필터링 및 정책 제어 ④ 파라미터 동결

164. NeMo Guardrails의 주요 역할은?
① GPU 자원 관리 ② 음성 합성 ③ 모델 압축 ④ 대화형 AI의 안전성과 신뢰성 강화

165. Guardrails에서 “flows”는 무엇을 정의하는가?
① 대화 정책과 제어 규칙 ② 학습률 스케줄 ③ 하이퍼파라미터 ④ 시각화 파이프라인

166. Guardrails에서 “rails”는 무엇을 의미하는가?
① 토큰 분리 규칙 ② 허용/금지되는 응답 행동 규칙 ③ GPU 제어 옵션 ④ 데이터 전처리 함수

167. Responsible AI 구현 시 가장 중요한 접근 방식은?
① 손실 감소 ② 속도 최적화 ③ 정책 기반 제어와 투명성 확보 ④ 모델 크기 증가

168. NVIDIA Riva의 주요 활용 분야는?
① 이미지 분류 ② 시각화 ③ 데이터 병합 ④ 실시간 음성 인식 및 합성

169. NVIDIA Triton Server의 장점은?
① 다양한 프레임워크 모델을 통합 배포 ② 시각화 전용 ③ CPU 전용 최적화 ④ 모델 학습 자동화

170. TensorRT의 주요 기능은?
① 데이터셋 병합 ② 추론 속도 향상 및 모델 최적화 ③ 하이퍼튜닝 ④ 손실함수 수정

171. TensorRT 최적화 중 “FP16 모드”의 의미는?
① 데이터 압축 ② 학습률 조절 ③ 반정밀도 연산으로 성능 및 효율 향상 ④ 손실 감소

172. TensorRT에서 “INT8 양자화”의 목적은?
① 정확도 향상 ② GPU 전력 감소 ③ 데이터 정규화 ④ 모델 크기 축소 및 추론 효율 개선

173. NVIDIA Triton과 TensorRT의 공통점은?
① 추론 성능 최적화와 배포 지원 ② 학습 자동화 ③ 데이터 정제 ④ 시각화 기능

174. RAG(Retrieval-Augmented Generation)의 구성 요소가 아닌 것은?
① Generator ② Scheduler ③ Vector Database ④ Retriever

175. RAG 구조의 장점은?
① 데이터 제거 ② 파라미터 감소 ③ 최신 지식 참조로 정확도 향상 ④ 모델 크기 축소

176. Vector Database가 필요한 이유는?
① 모델 저장 ② 토큰 필터링 ③ 파이프라인 병렬화 ④ 유사 문서 검색을 통한 문맥 확장

177. NVIDIA NeMo Toolkit이 지원하는 작업은?
① LLM 구성, 튜닝, 배포 ② GPU 클러스터 관리 ③ 데이터 압축 ④ 이미지 분류

178. NeMo Megatron 모델의 특징은?
① 소형 모델 최적화 ② 초대형 LLM 학습을 위한 병렬화 프레임워크 ③ 비지도 학습용 ④ 음성 모델 전용

179. NeMo가 지원하는 “prompt-tuning”의 장점은?
① 파라미터 효율 높음 ② 전체 학습 필요 없음 ③ 모두 해당 ④ 적은 자원으로 도메인 특화 조정 가능

180. NVIDIA Riva에서 TTS(Text-to-Speech) 모델의 역할은?
① 음성을 텍스트로 변환 ② 데이터 정규화 ③ 모델 최적화 ④ 텍스트를 음성으로 변환

181. Responsible AI의 구현에서 “Transparency”는?
① 모델의 의사결정 과정을 설명 가능하게 함 ② 속도 개선 ③ 데이터 암호화 ④ 성능 향상

182. “Privacy Preservation”의 핵심 기술은?
① Data Augmentation ② Differential Privacy ③ Dropout ④ Batch Normalization

183. Differential Privacy의 목적은?
① 속도 향상 ② 손실 최소화 ③ 개인 데이터 보호와 통계적 노이즈 추가 ④ 데이터 정규화

184. Explainable AI가 필요한 이유는?
① 속도 향상 ② 모델 압축 ③ 정확도 증가 ④ 인간이 AI 결정을 이해하고 신뢰할 수 있도록 함

185. Fairness 평가 시 사용되는 방법 중 하나는?
① 그룹별 성능 차이 분석 ② 손실 감소율 측정 ③ Dropout 비율 변경 ④ GPU 사용량 비교

186. AI 모델이 잘못된 결정을 내렸을 때 필요한 조치는?
① 학습률 증가 ② Error analysis 및 재학습 ③ 손실 함수 수정 ④ 데이터 축소

187. Ethical AI가 고려해야 할 요소는?
① GPU, 메모리, 전력 ② 손실, 정규화, 편향 ③ 투명성, 공정성, 책임성 ④ 속도, 정확도, 비용

188. RAG 구조에서 Retriever의 역할은?
① 모델 평가 ② 데이터 정규화 ③ 답변 생성 ④ 외부 지식에서 관련 문서 검색

189. NeMo Framework와 HuggingFace의 차이는?
① NeMo는 NVIDIA 생태계 통합용, HuggingFace는 범용 모델 허브 ② 둘 다 동일 기능 ③ HuggingFace는 상용 전용 ④ NeMo는 시각화 전용

190. Triton Server의 “Dynamic Batching” 기능은?
① 모델 전환 ② 요청을 자동 병합해 처리 효율 향상 ③ 학습률 자동 조절 ④ 메모리 정규화

191. TensorRT Engine의 목적은?
① 하이퍼파라미터 튜닝 ② 학습 데이터 저장 ③ GPU에서 최적화된 실행 그래프 생성 ④ 시각화 제공

192. NeMo의 Training Configuration에서 YAML 사용 이유는?
① 하이퍼파라미터 감소 ② 학습률 증가 ③ 데이터 시각화 ④ 구성 재현성 및 설정 관리 용이

193. Responsible AI 구현 시 가장 어려운 문제 중 하나는?
① 편향 탐지와 완화의 객관성 확보 ② 속도 조절 ③ 데이터 저장소 변경 ④ GPU 병목

194. Trustworthy AI 개발 시 고려해야 할 최종 목표는?
① 추론 속도 향상 ② 사회적 신뢰와 안전성 확보 ③ 모델 경량화 ④ 하이퍼튜닝 자동화

195. Fairness 문제를 해결하기 위한 기술적 접근은?
① Dropout ② LayerNorm ③ Re-sampling, Debiasing, Regularization ④ FP16

196. Toxic content 탐지를 위한 필터링 방식은?
① 샘플링 ② 데이터 압축 ③ 하이퍼튜닝 ④ 분류 모델 기반 콘텐츠 검출

197. Hallucination 감축을 위해 자주 사용되는 접근은?
① RAG와 외부 지식 베이스 결합 ② Dropout ③ 모델 축소 ④ 데이터 감소

198. Responsible AI에서 “Robustness”는 무엇을 뜻하는가?
① GPU 효율 ② 입력 변화에 강한 일관된 성능 ③ 정확도 향상 ④ 빠른 추론 속도

199. Trustworthy AI의 핵심 평가 항목으로 옳지 않은 것은?
① 설명가능성 ② 안전성 ③ 모델 크기 ④ 공정성

200. NVIDIA 생태계에서 Generative AI 솔루션을 통합하는 전략은?
① Riva 단독 사용 ② PyTorch 단독 사용 ③ HuggingFace 단독 실행 ④ NeMo + TensorRT + Triton + Guardrails 결합

201. NVIDIA Triton Inference Server에서 Model Repository의 역할은?
① 여러 모델을 버전별로 관리 및 배포 ② 로그 기록 전용 ③ 데이터셋 저장 ④ GPU 모니터링

202. Triton의 Ensemble 모델 기능은 무엇을 가능하게 하는가?
① 데이터 증강 ② 여러 모델을 파이프라인 형태로 연결한 추론 수행 ③ 모델 병합 후 단일 추론 ④ 하이퍼튜닝 자동화

203. TensorRT에서 Layer Fusion의 효과는?
① 모델 정확도 향상 ② 메모리 증가 ③ 연산 병합으로 추론 속도 향상 ④ 데이터 손실 감소

204. TensorRT의 Calibration 과정은 어떤 용도로 사용되는가?
① 손실함수 최적화 ② 학습률 조정 ③ 하이퍼파라미터 탐색 ④ 양자화(Quantization) 시 정밀도 보정

205. CUDA Stream을 활용하는 이유는?
① GPU 연산 병렬 실행 ② 손실 제어 ③ 모델 크기 축소 ④ 데이터 압축

206. cuDNN의 주요 역할은?
① 데이터 전처리 ② GPU 가속을 위한 딥러닝 연산 최적화 ③ 하이퍼튜닝 ④ 시각화

207. NVIDIA NeMo Megatron의 병렬화 전략 중 “Tensor Model Parallelism”이란?
① 배치 분할 ② 데이터 샘플 분할 ③ 모델의 가중치를 여러 GPU에 분산 계산 ④ 하이퍼파라미터 동기화

208. NeMo Megatron의 Pipeline Parallelism은 무엇을 의미하는가?
① 학습률 자동 조절 ② 데이터 로더 최적화 ③ 메모리 공유 ④ 모델의 레이어를 여러 GPU에 분할하여 순차 처리

209. Mixed Precision Training 시 FP16과 FP32를 혼합 사용하는 이유는?
① 연산 속도와 정확도 균형 확보 ② 학습률 증가 ③ 모델 크기 감소 ④ GPU 발열 감소

210. TensorRT에서 “Kernel Auto-Tuning”이 수행하는 일은?
① 손실 최소화 ② 최적의 GPU 커널 선택으로 실행 효율 극대화 ③ 파라미터 초기화 ④ 데이터 증강

211. NeMo Guardrails의 “config.yaml”에서 policy 설정의 역할은?
① 데이터 경로 지정 ② GPU 사용량 제한 ③ 대화 제한 규칙 및 허용 응답 제어 ④ 학습률 설정

212. RAG 시스템의 Retriever 단계에서 Vector Index의 역할은?
① 학습률 조정 ② 데이터 증강 ③ 파이프라인 병합 ④ 유사도 기반 빠른 검색 수행

213. RAG에서 Generator가 Retriever의 결과를 활용하는 방식은?
① 검색된 문서를 context로 활용해 답변 생성 ② 벡터 업데이트 ③ 검색 결과 필터링 ④ 파라미터 조정

214. NVIDIA AI Foundation Models의 목적은?
① 데이터 라벨링 ② 대규모 사전학습 모델을 API 형태로 제공 ③ 모델 압축 ④ GPU 제어

215. NVIDIA AI Workbench의 기능은?
① 하드웨어 관리 ② 데이터베이스 관리 ③ 로컬–클라우드 통합 개발 및 실험 환경 제공 ④ 이미지 렌더링
